# AdaptLight Raspberry Pi Testing Guide

## Overview

This document outlines the testing strategy for AdaptLight on Raspberry Pi. Tests are organized into:
- **Hardware Verification Scripts** (standalone, practical testing)
- **Unit tests** (individual components with pytest)
- **Integration tests** (combined functionality)

---

## Hardware Verification Scripts

These are standalone scripts for practical hardware testing. Run these FIRST to verify your hardware setup before running the automated test suite.

### Quick Start Hardware Tests

**Pin Connections Required:**
- **LED Strip (WS2812)**: Data â†’ GPIO 18, Power â†’ 5V, Ground â†’ GND
- **Button**: Terminal 1 â†’ GPIO 2, Terminal 2 â†’ GND
- **USB Microphone**: Plug into any USB port

**Test Order:**

1. **LED Test** - `sudo python3 test_leds.py`
   - Verifies LED strip connection on GPIO 18
   - Tests all colors: OFF â†’ RED â†’ GREEN â†’ BLUE â†’ WHITE â†’ Rainbow
   - Each color displays for 2 seconds

2. **Button Test** - `sudo python3 test_button.py`
   - Verifies button connection on GPIO 2
   - Counts and times each button press
   - Tests debouncing (50ms)
   - Press Ctrl+C to see results

3. **Microphone Test** - `python3 test_microphone.py`
   - Lists available audio devices
   - Tests audio levels (5 seconds)
   - Records test file: test_recording.wav
   - Play with: `aplay test_recording.wav`

4. **OpenAI API Test** - `python3 test_openai.py`
   - Loads config.yaml from current directory
   - Tests GPT text completion
   - Tests Whisper speech-to-text (if test_recording.wav exists)
   - Verifies API connectivity

5. **Integrated System Test** - `sudo python3 test_integrated.py`
   - Tests full workflow: button â†’ record â†’ transcribe â†’ respond â†’ LED feedback
   - LED colors: BLUE (idle), WHITE (listening), YELLOW (processing), GREEN (success), RED (error)
   - Press button, speak for 5 seconds, see results
   - Can run multiple test cycles

**Troubleshooting:**
- LEDs not working? Check power, connect data to MOSI (GPIO 10), run with sudo
- Enable SPI: `sudo raspi-config` â†’ Interface Options â†’ SPI â†’ Enable
- Raspberry Pi 5: Use `pip install adafruit-circuitpython-neopixel-spi adafruit-blinka`
- Button not responding? Check GPIO 2 and GND connections
- No audio? Run `arecord -l`, check USB connection
- API errors? Verify openai.api_key in config.yaml

---

## Unit Tests

### 1. LED Control Test (`test_led_control.py`)

**Purpose**: Verify NeoPixel LED strip control

**Test Cases**:
- âœ… Initialize LED controller
- âœ… Set color to red (255, 0, 0)
- âœ… Set color to green (0, 255, 0)
- âœ… Set color to blue (0, 0, 255)
- âœ… Set color to white (255, 255, 255)
- âœ… Turn LEDs off (0, 0, 0)
- âœ… Set brightness levels (0.1, 0.5, 1.0)
- âœ… Fill all LEDs with same color
- âœ… Cleanup and verify LEDs off

**Hardware Required**:
- NeoPixel LED strip (16 LEDs)
- GPIO 18 connection

**Run**:
```bash
cd raspi
python test_led_control.py
```

---

### 2. Button Input Test (`test_button_input.py`)

**Purpose**: Verify button press pattern detection

**Test Cases**:
- âœ… Single click detection
- âœ… Double click detection (within 200ms window)
- âœ… Hold detection (500ms threshold)
- âœ… Release after hold detection
- âœ… Debouncing (50ms)
- âœ… Callback execution for each event type

**Hardware Required**:
- Push button connected to GPIO 2
- Ground connection

**Run**:
```bash
cd raspi
python test_button_input.py
```

**Expected Output**:
```
Testing button controller...
Press button for SINGLE CLICK... <wait for input>
âœ“ Single click detected
Press button for DOUBLE CLICK... <wait for input>
âœ“ Double click detected
Press and HOLD button... <wait for input>
âœ“ Hold detected
Release button... <wait for input>
âœ“ Release detected
```

---

### 3. Voice Recording Test (`test_voice_recording.py`)

**Purpose**: Verify audio recording from microphone

**Test Cases**:
- âœ… Detect USB microphone
- âœ… Record audio when button held
- âœ… Save to MP3 format
- âœ… Stop recording on button release
- âœ… Verify audio file created
- âœ… Play back recorded audio
- âœ… Check audio duration matches recording time

**Hardware Required**:
- USB microphone
- Recording button (GPIO 3 or configurable)

**Recording Flow**:
1. Hold recording button â†’ Start recording
2. Speak into microphone
3. Release button â†’ Stop recording
4. Save as MP3 file (`recordings/test_TIMESTAMP.mp3`)

**Run**:
```bash
cd raspi
python test_voice_recording.py
```

**Expected Output**:
```
Testing voice recording...
Hold recording button to start...
ğŸ”´ Recording... (speak now)
Release button to stop...
â¹ï¸  Recording stopped
âœ“ Saved: recordings/test_20250106_103045.mp3
âœ“ Duration: 3.2s
âœ“ File size: 52KB
```

---

### 4. Speech-to-Text Test (`test_speech_to_text.py`)

**Purpose**: Verify STT API integration (Whisper/Google/Vosk)

**Test Cases**:
- âœ… Load audio file (MP3/WAV)
- âœ… Send to Whisper API
- âœ… Receive transcribed text
- âœ… Handle API errors
- âœ… Test with sample phrases:
  - "Turn on the light"
  - "Make it red"
  - "Pulse slowly"
  - "Turn it off"
- âœ… Verify text accuracy

**Prerequisites**:
- OpenAI API key in `config.yaml`
- Sample audio files in `test_audio/`

**Run**:
```bash
cd raspi
python test_speech_to_text.py
```

**Expected Output**:
```
Testing speech-to-text...

Test 1: test_audio/turn_on.mp3
Audio: [plays audio]
Transcription: "turn on the light"
âœ“ Match expected

Test 2: test_audio/make_red.mp3
Audio: [plays audio]
Transcription: "make it red"
âœ“ Match expected

All STT tests passed!
```

---

## Integration Tests

### Level 1: API Call Test (`test_api_basic.py`)

**Purpose**: Test OpenAI API for command parsing (no hardware)

**Test Cases**:
- âœ… Send text command to parsing API
- âœ… Receive JSON rules array
- âœ… Validate rule structure
- âœ… Test various commands:
  - "turn on the light"
  - "make it blue"
  - "pulse slowly"

**No Hardware Required** - API only

**Run**:
```bash
cd raspi
python test_api_basic.py
```

**Expected Output**:
```
Testing OpenAI API parsing...

Input: "turn on the light"
Current state: "off"
Response: [
  {
    "state1": "off",
    "transition": "voice_command",
    "state2": "on",
    "state2_param": null
  }
]
âœ“ Valid JSON
âœ“ Rule structure correct

Input: "make it blue"
Current state: "on"
Response: [
  {
    "state1": "on",
    "transition": "voice_command",
    "state2": "color",
    "state2_param": {"r": 0, "g": 0, "b": 255}
  }
]
âœ“ Valid JSON
âœ“ State-aware (uses current state)

All API tests passed!
```

---

### Level 2: API + State Manipulation Test (`test_api_state.py`)

**Purpose**: Test command parsing with state machine logic

**Test Cases**:
- âœ… Initialize state machine
- âœ… Parse command into rules
- âœ… Add rules to state machine
- âœ… Execute transitions
- âœ… Verify state changes
- âœ… Test prompt matching:
  - From "off" â†’ "turn it red" â†’ should go to "color"
  - From "color" â†’ "make it pulse" â†’ should go to "animation"
  - From "animation" â†’ "turn it off" â†’ should go to "off"

**No Hardware Required** - State machine only

**Run**:
```bash
cd raspi
python test_api_state.py
```

**Expected Output**:
```
Testing API + State Machine...

Test 1: off â†’ "turn it red" â†’ color
Current state: off
Parsed rules: [{state1: "off", transition: "voice_command", state2: "color", ...}]
Added 1 rule(s)
Executing transition: voice_command
New state: color
âœ“ Correct state transition
âœ“ Color params: r=255, g=0, b=0

Test 2: color â†’ "make it pulse" â†’ animation
Current state: color
Parsed rules: [{state1: "color", transition: "voice_command", state2: "animation", ...}]
Added 1 rule(s)
Executing transition: voice_command
New state: animation
âœ“ Correct state transition
âœ“ Animation params present

All state tests passed!
```

---

### Level 3: Full Integration Test (`test_full_integration.py`)

**Purpose**: End-to-end test with all components (hardware + software)

**Test Cases**:
- âœ… Initialize all components (LEDs, buttons, state machine, voice)
- âœ… Test button â†’ LED response
- âœ… Test voice recording â†’ transcription â†’ parsing â†’ LED change
- âœ… Test logging (voice commands, button events, state changes)
- âœ… Verify log files created
- âœ… Test complete workflow:
  1. Click button â†’ LED turns on
  2. Hold recording button â†’ Record "make it red"
  3. Release â†’ Transcribe â†’ Parse â†’ LED turns red
  4. Click button â†’ LED turns off

**Hardware Required**:
- ALL hardware (LEDs, buttons, microphone)
- Internet connection (for API calls)

**Run**:
```bash
cd raspi
sudo python test_full_integration.py
```

**Expected Output**:
```
AdaptLight Full Integration Test
================================

âœ“ LED Controller initialized
âœ“ Button Controller initialized
âœ“ State Machine initialized
âœ“ Voice Input initialized
âœ“ Command Parser initialized
âœ“ Event Logger initialized

Test 1: Button Click â†’ LED On
Press button now...
âœ“ Button click detected
âœ“ State changed: off â†’ on
âœ“ LED turned on (white)
âœ“ Event logged

Test 2: Voice Command â†’ LED Color Change
Hold recording button and say "make it red"...
ğŸ”´ Recording...
âœ“ Recording complete
âœ“ Transcribed: "make it red"
âœ“ Parsed 1 rule(s)
âœ“ State changed: on â†’ color
âœ“ LED color: RGB(255, 0, 0)
âœ“ Voice command logged

Test 3: Verify Logs
âœ“ Log file created: data/logs/button_events/log-2025-01-06.jsonl
âœ“ Log file created: data/logs/voice_commands/log-2025-01-06.jsonl
âœ“ Log file created: data/logs/state_changes/log-2025-01-06.jsonl

All integration tests passed! ğŸ‰
```

---

## Test File Structure

```
raspi/
â”œâ”€â”€ HARDWARE VERIFICATION SCRIPTS (run first):
â”œâ”€â”€ test_leds.py                 # Hardware: LED strip verification
â”œâ”€â”€ test_button.py               # Hardware: Button input verification
â”œâ”€â”€ test_microphone.py           # Hardware: USB mic verification
â”œâ”€â”€ test_openai.py               # Hardware: API connectivity test
â”œâ”€â”€ test_integrated.py           # Hardware: Full system workflow test
â”‚
â”œâ”€â”€ UNIT TESTS (pytest):
â”œâ”€â”€ test_led_control.py          # Unit test: LED control
â”œâ”€â”€ test_button_input.py         # Unit test: Button patterns
â”œâ”€â”€ test_voice_recording.py      # Unit test: Audio recording
â”œâ”€â”€ test_speech_to_text.py       # Unit test: STT API
â”‚
â”œâ”€â”€ INTEGRATION TESTS (pytest):
â”œâ”€â”€ test_api_basic.py            # Integration Level 1: API only
â”œâ”€â”€ test_api_state.py            # Integration Level 2: API + State
â”œâ”€â”€ test_full_integration.py     # Integration Level 3: Full E2E
â”‚
â”œâ”€â”€ TEST DATA:
â”œâ”€â”€ test_audio/                  # Sample audio files for STT tests
â”‚   â”œâ”€â”€ turn_on.mp3
â”‚   â”œâ”€â”€ make_red.mp3
â”‚   â””â”€â”€ pulse.mp3
â”œâ”€â”€ recordings/                  # Recorded audio output
â”‚   â””â”€â”€ test_*.mp3
â””â”€â”€ test_recording.wav           # Generated by test_microphone.py
```

---

## Running All Tests

### Step 1: Hardware Verification (Run First!)
```bash
cd worktree/raspi

# Test LEDs
sudo python3 test_leds.py

# Test Button
sudo python3 test_button.py

# Test Microphone
python3 test_microphone.py

# Test OpenAI API
python3 test_openai.py

# Test Full Integration
sudo python3 test_integrated.py
```

### Step 2: Run Unit Tests (pytest)
```bash
cd worktree/raspi
python -m pytest test_led_control.py test_button_input.py test_voice_recording.py test_speech_to_text.py
```

### Step 3: Run Integration Tests (pytest)
```bash
cd worktree/raspi
python -m pytest test_api_basic.py test_api_state.py
```

### Step 4: Run Full E2E Test (requires hardware)
```bash
cd worktree/raspi
sudo python test_full_integration.py
```

### Run All Tests
```bash
cd worktree/raspi
./run_all_tests.sh
```

---

## Test Results Log

Results will be logged to `test_results.log`:

```
[2025-01-06 10:30:00] test_led_control.py: PASSED (8/8 tests)
[2025-01-06 10:30:15] test_button_input.py: PASSED (6/6 tests)
[2025-01-06 10:30:45] test_voice_recording.py: PASSED (7/7 tests)
[2025-01-06 10:31:20] test_speech_to_text.py: PASSED (5/5 tests)
[2025-01-06 10:31:45] test_api_basic.py: PASSED (3/3 tests)
[2025-01-06 10:32:10] test_api_state.py: PASSED (3/3 tests)
[2025-01-06 10:33:00] test_full_integration.py: PASSED (3/3 tests)
```

---

## Troubleshooting

### LED not working
- Check GPIO 18 connection
- Run with `sudo` for GPIO permissions
- Verify power supply to LED strip

### Button not responding
- Check GPIO 2 connection and ground
- Adjust debounce time in config
- Test with multimeter

### Audio recording fails
- Check USB microphone: `arecord -l`
- Verify permissions: `sudo usermod -a -G audio $USER`
- Test microphone: `arecord -d 3 test.wav`

### STT API errors
- Verify API key in `config.yaml`
- Check internet connection
- Test API manually: `curl https://api.openai.com/v1/audio/transcriptions`

---

## Next Steps

After all tests pass:
1. Run full system: `python main.py`
2. Monitor logs: `tail -f data/logs/**/*.jsonl`
3. Test voice commands in real environment
4. Deploy as systemd service for auto-start
